import os
import json
import re
import asyncio
import operator
import time
from typing import Annotated, Sequence, TypedDict, Dict, List
from langgraph.graph import StateGraph, END
from langchain_groq import ChatGroq
from langchain_core.messages import HumanMessage
from dotenv import load_dotenv

# åŒ¯å…¥ Phase 1 & 2
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Standardize import to the gymnasium-compliant version
from Trading_lab import train_and_export_logs, get_trading_data

load_dotenv()

# --- 1. å®šç¾©ç‹€æ…‹ ---
class AgentState(TypedDict):
    iteration: int
    train_logs: Dict
    diagnostic_report: str
    generated_code: str
    is_satisfied: bool
    history: Annotated[List[str], operator.add]

# --- 2. è¨ºæ–·ç¯€é» (Pathologist) ---
async def ai_pathologist_node(state: AgentState):
    iter_num = state['iteration']
    print(f"\nğŸ§ [Node: Pathologist] ç¬¬ {iter_num} è¼ªè¨ºæ–·ä¸­...")
    
    # ä½¿ç”¨ Groq (é€Ÿåº¦å¿«)
    llm = ChatGroq(model="llama-3.3-70b-versatile", temperature=0, max_retries=0)
    
    prompt = f"""
    ä½ æ˜¯ RL é‡åŒ–äº¤æ˜“è¨ºæ–·å°ˆå®¶ã€‚ç•¶å‰æ¨¡å‹æŒ‡æ¨™ï¼š
    - Explained Variance: {state['train_logs']['explained_variance']} (ç›®æ¨™ > 0.5)
    - Value Loss: {state['train_logs']['value_loss']}
    - Sharpe Ratio: {state['train_logs']['sharpe_ratio']}
    
    å¦‚æœ Explained Variance å¾ˆä½ (<0.1)ï¼Œä»£è¡¨çå‹µå‡½æ•¸æ²’å­¸åˆ°æ±è¥¿ã€‚
    è«‹åˆ¤æ–·æ˜¯å¦æ»¿æ„ (is_satisfied)ã€‚
    å›å‚³ç´” JSON: {{ "diagnosis": "ç°¡çŸ­åˆ†æ", "is_satisfied": true/false }}
    """
    
    result = {"diagnosis": "API æˆ–è§£æéŒ¯èª¤", "is_satisfied": False}
    max_retries = 5
    base_wait_time = 60  # åŸºç¤ç­‰å¾…æ™‚é–“ (ç§’)

    for attempt in range(max_retries):
        try:
            response = await llm.ainvoke([HumanMessage(content=prompt)])
            res_text = response.content.replace("```json", "").replace("```", "").strip()
            
            match = re.search(r'\{.*\}', res_text, re.DOTALL)
            result = json.loads(match.group()) if match else json.loads(res_text)
            break # æˆåŠŸå‰‡è·³å‡ºè¿´åœˆ
        except Exception as e:
            if "RESOURCE_EXHAUSTED" in str(e) or "429" in str(e):
                wait_time = base_wait_time * (attempt + 1)
                print(f"âš ï¸ API Rate Limit (429). ä¼‘æ¯ {wait_time} ç§’å¾Œé‡è©¦ ({attempt+1}/{max_retries})...")
                await asyncio.sleep(wait_time)
            else:
                print(f"âš ï¸ è¨ºæ–·å¤±æ•—: {e}ï¼Œåˆ¤å®šç‚ºä¸æ»¿æ„")
                result = {"diagnosis": f"éŒ¯èª¤: {str(e)}", "is_satisfied": False}
                break
        
    print(f"   ğŸ“Š è¨ºæ–·: {result['diagnosis']} (Pass: {result['is_satisfied']})")
    
    return {
        "diagnostic_report": result["diagnosis"],
        "is_satisfied": result["is_satisfied"],
        "history": [f"Iter {iter_num}: {result['diagnosis']}"]
    }

# --- 3. ä»£ç¢¼ç”Ÿæˆç¯€é» (Refiner) ---
async def strategy_refiner_node(state: AgentState):
    print("\nğŸ’¡ [Node: Refiner] æ­£åœ¨æ’°å¯« Python çå‹µå‡½æ•¸...")
    
    # ä½¿ç”¨ Groq (èƒ½åŠ›å¼·)
    llm = ChatGroq(model="llama-3.3-70b-versatile", temperature=0.7, max_retries=0)
    
    prompt = f"""
    è¨ºæ–·ï¼š{state['diagnostic_report']}
    
    è«‹é‡å¯« Python çå‹µå‡½æ•¸ `calculate_reward` ä¾†æ”¹å–„æ¨¡å‹ã€‚
    å‡½æ•¸ç°½åï¼šdef calculate_reward(net_worth, prev_net_worth, action, shares_held):
    
    é‚è¼¯å»ºè­°ï¼š
    1. **çå‹µç¸®æ”¾ (Scaling)**: åŸå§‹æ”¶ç›Šç‡æ•¸å€¼å¤ªå° (e.g., 0.001)ï¼Œè«‹å°‡æ”¶ç›Šç‡ * 100 æˆ– * 1000ï¼Œè®“æ¨¡å‹æ›´å®¹æ˜“å­¸ç¿’ã€‚
    2. **å‹•ä½œçå‹µ**: 
       - å¦‚æœ action==1 (Hold) ä¸”è¶¨å‹¢å‘ä¸Šï¼Œçµ¦äºˆå¾®å°çå‹µã€‚
       - å¦‚æœ action==2 (Buy) ä¸”éš¨å¾Œ net_worth ä¸Šå‡ï¼Œçµ¦äºˆå¤§çå‹µã€‚
    3. **é¢¨éšªæ‡²ç½°**: å¦‚æœ net_worth < prev_net_worthï¼Œçµ¦äºˆæ›´å¤§çš„æ‡²ç½° (e.g., æå¤± * 1.5)ã€‚
    4. **èªæ³•å®‰å…¨**: 
       - ä¸è¦å¼•ç”¨å¤–éƒ¨æœªå®šç¾©è®Šæ•¸ã€‚
       - ç¢ºä¿é™¤æ³•ä¸ç‚ºé›¶ã€‚
    
    åªå›å‚³ Python ä»£ç¢¼å€å¡Š (```python ... ```)ã€‚
    """
    
    code = "def calculate_reward(net_worth, prev_net_worth, action, shares_held):\n    return (net_worth - prev_net_worth) / prev_net_worth"
    max_retries = 5
    base_wait_time = 60

    for attempt in range(max_retries):
        try:
            response = await llm.ainvoke([HumanMessage(content=prompt)])
            code_match = re.search(r"```python(.*?)```", response.content, re.DOTALL)
            code = code_match.group(1).strip() if code_match else response.content.strip()
            break
        except Exception as e:
            if "RESOURCE_EXHAUSTED" in str(e) or "429" in str(e):
                wait_time = base_wait_time * (attempt + 1)
                print(f"âš ï¸ API Rate Limit (429). ä¼‘æ¯ {wait_time} ç§’å¾Œé‡è©¦ ({attempt+1}/{max_retries})...")
                await asyncio.sleep(wait_time)
            else:
                print(f"âš ï¸ ç”Ÿæˆå¤±æ•—: {e}")
                break
    
    print(f"   ğŸ’» AI å·²ç”Ÿæˆæ–°ç­–ç•¥ (é•·åº¦: {len(code)} chars)")
    return {
        "generated_code": code,
        "iteration": state["iteration"] + 1,
        "history": [f"Iter {state['iteration']}: Code Generated"]
    }

# --- 4. åŸ·è¡Œè¨“ç·´ç¯€é» (Executor) ---
def execution_node(state: AgentState):
    print("\nâš™ï¸ [Node: Executor] æ³¨å…¥ä»£ç¢¼ä¸¦é‡å•Ÿè¨“ç·´...")
    
    # å‹•æ…‹åŸ·è¡Œä»£ç¢¼
    local_scope = {}
    try:
        exec(state["generated_code"], globals(), local_scope)
        reward_func = local_scope.get("calculate_reward")
        if not reward_func: raise ValueError("å‡½æ•¸åç¨±éŒ¯èª¤")
    except Exception as e:
        print(f"âŒ ä»£ç¢¼æ³¨å…¥å¤±æ•—: {e}ï¼Œä½¿ç”¨é è¨­è¨“ç·´")
        reward_func = None
        
    # å‘¼å« Trading_Lab
    if 'data_cache' not in globals():
        globals()['data_cache'] = get_trading_data()
    
    logs, _ = train_and_export_logs(globals()['data_cache'], custom_reward_func=reward_func)
    
    return {"train_logs": logs}

# --- 5. æ§‹å»ºåœ–å½¢ ---
def build_quant_brain():
    workflow = StateGraph(AgentState)
    workflow.add_node("pathologist", ai_pathologist_node)
    workflow.add_node("refiner", strategy_refiner_node)
    workflow.add_node("executor", execution_node)
    
    workflow.set_entry_point("pathologist")
    
    def router(state):
        if state["is_satisfied"] or state["iteration"] > 3: # æœ€å¤šè·‘ 3 è¼ª
            return END
        return "refiner"
    
    workflow.add_conditional_edges("pathologist", router)
    workflow.add_edge("refiner", "executor")
    workflow.add_edge("executor", "pathologist")
    
    return workflow.compile()

if __name__ == "__main__":
    # åˆå§‹ç‹€æ…‹
    initial_state = {
        "iteration": 1,
        "train_logs": {"explained_variance": -1.0, "value_loss": 1.0, "sharpe_ratio": 0.0},
        "diagnostic_report": "",
        "generated_code": "",
        "is_satisfied": False,
        "history": []
    }
    
    print("ğŸš€ å•Ÿå‹• RL é‡åŒ–äº¤æ˜“ Agent...")
    app = build_quant_brain()
    asyncio.run(app.ainvoke(initial_state))
